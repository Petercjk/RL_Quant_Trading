# RL Quantitative Trading Agent (A-Share)
# åŸºäºå¼ºåŒ–å­¦ä¹ çš„é‡åŒ–äº¤æ˜“æ™ºèƒ½ä½“

> ğŸš§ Work in Progress / æ–½å·¥ä¸­**
>
> This repository is currently under active development for my undergraduate thesis.
> æœ¬é¡¹ç›®ä¸ºæˆ‘çš„æœ¬ç§‘æ¯•ä¸šè®ºæ–‡ä»£ç åº“ï¼Œç›®å‰æ­£åœ¨æŒç»­å¼€å‘å’Œæ›´æ–°ä¸­ã€‚

---

## Introduction / é¡¹ç›®ç®€ä»‹

Welcome! This is the repository for my undergraduate thesis: "Design and Implementation of a Reinforcement Learning-based Quantitative Trading Agent".

In simple terms, I'm training AI agents (using RL) to find profitable trading strategies within the complex environment of the Chinese A-share market. Instead of just predicting prices, the agent is learning how to make decisions (buy/sell/hold) to optimize portfolio value over time.

æ¬¢è¿ï¼è¿™æ˜¯æˆ‘çš„æœ¬ç§‘æ¯•ä¸šè®ºæ–‡ã€ŠåŸºäºå¼ºåŒ–å­¦ä¹ çš„é‡åŒ–äº¤æ˜“æ™ºèƒ½ä½“è®¾è®¡ä¸å®ç°ã€‹çš„ä»£ç ä»“åº“ã€‚

ç®€å•æ¥è¯´ï¼Œæˆ‘æ­£åœ¨å°è¯•åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•ï¼Œè®­ç»ƒä¸€ä¸ªèƒ½åœ¨ä¸­å›½Aè‚¡å¸‚åœºé‡Œåˆ¶å®šç­–ç•¥çš„AIæ™ºèƒ½ä½“ã€‚ä¸ä¼ ç»Ÿè‚¡ä»·é¢„æµ‹ä¸åŒï¼Œè¿™ä¸ªé¡¹ç›®çš„æ ¸å¿ƒåœ¨äºè®­ç»ƒæ™ºèƒ½ä½“å­¦ä¼šåœ¨åŠ¨æ€çš„å¸‚åœºç¯å¢ƒä¸­åšå†³ç­–ï¼ˆä¹°å…¥ã€å–å‡ºæˆ–æŒä»“ï¼‰ï¼Œä»è€Œå®ç°èµ„äº§å¢å€¼ã€‚

## Key Features / æ ¸å¿ƒå†…å®¹

* Market: Chinese A-Share market (T+1 trading rule, price limits, etc).
    * å¸‚åœºï¼š èšç„¦ä¸­å›½ A è‚¡ï¼ˆè€ƒè™‘ T+1ã€æ¶¨è·Œåœé™åˆ¶ç­‰ç‰¹æœ‰è§„åˆ™ï¼‰ã€‚
* Method: Deep Reinforcement Learning (PPO algorithm focus).
    * æ–¹æ³•ï¼š æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆPPO ç®—æ³•ç­‰ï¼‰ã€‚
* Evaluation: Focusing on Online Trading simulation, not just backtesting on training data.
    * è¯„ä¼°ï¼š é‡ç‚¹åœ¨äºæ¨¡æ‹Ÿå®ç›˜å†³ç­–ï¼Œä¸ä»…ä»…æ˜¯å†å²æ•°æ®çš„ç®€å•å›æµ‹ã€‚
* Data Source: Tushare API (Data is not included in this repo).
    * æ•°æ®æºï¼šTushare APIï¼ˆåŸå§‹æ•°æ®æ–‡ä»¶ä¸åŒ…å«åœ¨ä»“åº“ä¸­ï¼‰ã€‚

## Project Structure / é¡¹ç›®ç»“æ„

Here is how the project is organized. This structure is designed to separate configuration, core logic, and experimental results.
è¿™é‡Œæ˜¯é¡¹ç›®ç»“æ„å®‰æ’ã€‚é¡¹ç›®é‡‡ç”¨äº†æ¨¡å—åŒ–ç»“æ„è®¾è®¡ï¼Œå°†é…ç½®ã€æ ¸å¿ƒé€»è¾‘ä¸å®éªŒç»“æœåˆ†ç¦»ï¼Œä»¥ä¾¿äºå¤ç°å’Œæ‰©å±•ã€‚

```text
RL_Quant_Trading/
â”‚
â”œâ”€â”€ configs/                   # Configuration files (YAML)
â”‚   â”œâ”€â”€ env/                   # Environment settings (transaction cost, window size)
â”‚   â”œâ”€â”€ agent/                 # Agent hyperparameters (PPO, A2C, etc.)
â”‚   â””â”€â”€ experiment/            # Experiment protocols
â”‚
â”œâ”€â”€ data/                      # Data storage (Ignored by Git)
â”‚   â”œâ”€â”€ raw/                   # downloaded from Tushare
â”‚   â””â”€â”€ processed/             # Cleaned and feature-engineered data
â”‚
â”œâ”€â”€ src/                       # Core Source Code
â”‚   â”œâ”€â”€ agents/                # RL Agent implementations
â”‚   â”œâ”€â”€ envs/                  # Custom Trading Environments (Gym-compatible)
â”‚   â”œâ”€â”€ models/                # Neural Network architectures (PyTorch)
â”‚   â”œâ”€â”€ utils/                 # Utilities (Logger, Seed, etc.)
â”‚   â””â”€â”€ data_processing/       # Data cleaning and feature engineering scripts
â”‚
â”œâ”€â”€ train/                     # Training Scripts
â”‚   â””â”€â”€ train_agent.py         
â”‚
â”œâ”€â”€ online/                    # Online / Rolling Prediction (Core)
â”‚   â”œâ”€â”€ online_trader.py       # Simulating real-world trading decisions
â”‚   â””â”€â”€ rolling_test.py        # Walk-forward analysis
â”‚
â”œâ”€â”€ hyperparam_search/         # Hyperparameter Tuning
â”‚
â”œâ”€â”€ experiments/               # Experiment Results (Logs, Plots, Checkpoints)
â”‚
â””â”€â”€ docs/                      # Documentation & Notes